{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.2.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (6.0 kB)\n",
      "Downloading mysql_connector_python-9.2.0-cp311-cp311-macosx_14_0_arm64.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipyfilechooser\n",
      "  Downloading ipyfilechooser-0.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: ipywidgets in ./.conda/lib/python3.11/site-packages (from ipyfilechooser) (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.conda/lib/python3.11/site-packages (from ipywidgets->ipyfilechooser) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.conda/lib/python3.11/site-packages (from ipywidgets->ipyfilechooser) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.conda/lib/python3.11/site-packages (from ipywidgets->ipyfilechooser) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.conda/lib/python3.11/site-packages (from ipywidgets->ipyfilechooser) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.conda/lib/python3.11/site-packages (from ipywidgets->ipyfilechooser) (3.0.13)\n",
      "Requirement already satisfied: decorator in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./.conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->ipyfilechooser) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.conda/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.conda/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.conda/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in ./.conda/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->ipyfilechooser) (0.2.3)\n",
      "Downloading ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: ipyfilechooser\n",
      "Successfully installed ipyfilechooser-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipyfilechooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytesseract opencv-python-headless pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "from tkinter import Tk, filedialog\n",
    "import os\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "# Function to extract text using Tesseract OCR\n",
    "def extract_text(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "# Function to process text using NLP and extract relevant information\n",
    "def process_text(text, keywords=[]):\n",
    "    doc = nlp(text)\n",
    "    extracted_info = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if any(keyword.lower() in ent.text.lower() for keyword in keywords):\n",
    "            extracted_info.append({\"Text\": ent.text, \"Label\": ent.label_})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "# Function to select image using a button in Jupyter Notebook\n",
    "def select_image(_):\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askopenfilename(title=\"Select an Image\", filetypes=[(\"JPEG Files\", \"*.jpg\"), (\"PNG Files\", \"*.png\"), (\"JPEG Files\", \"*.jpeg\")])\n",
    "\n",
    "    if file_path and os.path.exists(file_path):\n",
    "        process_image_jupyter(file_path)\n",
    "    else:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(\"Error: No valid file selected.\")\n",
    "\n",
    "# Function to process selected image within Jupyter environment\n",
    "def process_image_jupyter(image_path):\n",
    "    try:\n",
    "        text = extract_text(image_path)\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the image.\")\n",
    "                return\n",
    "\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"date\", \"amount\", \"name\", \"address\", \"Name:\", \"Customer Name\", \"Recipient\", \"Amount:\", \"Date:\", \"Address:\", \"ID:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "button = widgets.Button(description=\"Select Image\")\n",
    "button.on_click(select_image)\n",
    "\n",
    "display(button, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f811dfd8f94dc39556971d3136ecaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3957cbd73445c2af52ba7131729132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Date:\", \"Date\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d/]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d]+)\")\n",
    "        elif keyword in [\"ID:\", \"ID\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d]+)\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):  # Use finditer to find all matches\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Remove any text after \"\\n\"\n",
    "            extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Address:\", \"Date:\", \"Amount:\", \"ID:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d8992be29248a583cab36d24065aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d90c73dbb64d9fa8e24085e783bfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Date:\", \"Date\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d/]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d]+)\")\n",
    "        elif keyword in [\"ID:\", \"ID\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d]+)\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):  # Use finditer to find all matches\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Remove any text after \"\\n\"\n",
    "            extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        for item in data:\n",
    "            query = \"INSERT INTO extracted_data (text, label) VALUES (%s, %s)\"\n",
    "            values = (item[\"Text\"], item[\"Label\"])\n",
    "            cursor.execute(query, values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Address:\", \"Date:\", \"Amount:\", \"ID:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "                save_to_database(important_info)  # Save to database here\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current implementation will indeed lead to a problem when using the stored data in the future. Each time you process a new document and extract information, it is being appended to the same extracted_data table. This means you will have a growing list of all the extracted information, without any clear distinction between the data from different documents.\n",
    "\n",
    "Here's a breakdown of why this is a problem and how it could cause issues:\n",
    "\n",
    "Data Mixing: All the extracted \"Name,\" \"Address,\" \"Date,\" \"Amount,\" and \"ID\" will be in a single table, making it difficult to associate specific details with their original document.\n",
    "Difficulty in Analysis: If you want to analyze the data, for example, to see the total number of claims for a specific date range or identify claims from a particular customer, it will be very challenging to filter and group the data correctly.\n",
    "Redundancy: If you process multiple documents from the same claim or the same person, you might end up with redundant entries in the database.\n",
    "Query Complexity: Writing queries to retrieve specific information will become more complex and prone to errors.\n",
    "\n",
    "Hence, the following changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335b7560a3104447a6efb2dac76fcf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a154ebcd16144acb9f7fdeb3ea8085e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Date:\", \"Date\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d/]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d]+)\")\n",
    "        elif keyword in [\"ID:\", \"ID\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d]+)\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):  # Use finditer to find all matches\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Remove any text after \"\\n\"\n",
    "            extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, document_id):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        for item in data:\n",
    "            query = \"INSERT INTO extracted_data (document_id, text, label) VALUES (%s, %s, %s)\"\n",
    "            values = (document_id, item[\"Text\"], item[\"Label\"])\n",
    "            cursor.execute(query, values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Address:\", \"Date:\", \"Amount:\", \"ID:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                # Save document information to the 'documents' table\n",
    "                cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "                cursor = cnx.cursor()\n",
    "                insert_doc_query = \"INSERT INTO documents (file_path) VALUES (%s)\"\n",
    "                doc_values = (file_path,)\n",
    "                cursor.execute(insert_doc_query, doc_values)\n",
    "                cnx.commit()\n",
    "                document_id = cursor.lastrowid  # Get the auto-generated ID\n",
    "                cursor.close()\n",
    "                cnx.close()\n",
    "\n",
    "                # Save extracted information with the document_id\n",
    "                save_to_database(important_info, document_id)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to make some changes. The changes I would like are is that I want to extract more key information that must include:\n",
    "Name, Father's Name, Adhaar Card, Gender, Blood Group, Address, Hospital Name, Insurance id,Appointment time, phone number,amount, disease_name,diesease_details, Medicines needed including injections,oral,etc and also Bedtype details including bedtype and ventilation: yes/no as well as if other charges. Before the primary key was document_id was the primary key, now I want to make the insurance_id as the primary key.\n",
    "To not confuse with the previous tables and its already stored data I would suggest to create new tables. Do the proper changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299907c9c4a64d76a6f802e31e0b3bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a660c334360744279cf6552570be2578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142b054e38074d4c94c270f91aa8f5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408d177d6bcb4f8682bdcbe09d12843d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\", \"Patient Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w\\s]+(?:[\\n\\w\\s]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Father's Name:\", \"Father Name:\"]:\n",
    "            pattern = re.compile(rf\"(?<!\\w){keyword}:\\s*([\\w\\s]+(?:[\\n\\w\\s]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Aadhar Card:\", \"Aadhaar:\", \"Aadhar No:\", \"Aadhar\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\d\\s-]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Gender:\", \"Sex:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Blood Group:\", \"Blood:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w+-]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w\\s,-]+(?:[\\n\\w\\s,-]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Hospital Name:\", \"Hospital\"]:\n",
    "            pattern = re.compile(rf\"(?<!\\w){keyword}:\\s*([\\w\\s]+(?:[\\n\\w\\s]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Insurance ID:\", \"InsuranceID:\", \"Insurance Id\", \"Insurance\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w\\d-]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Appointment Time:\", \"Appointment\", \"Time:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\d:]+(?:\\s*[AP]M)?)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Phone:\", \"Phone Number:\", \"Contact:\", \"Mobile:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\d\\s-]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Amount:\", \"Amount\", \"Total:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\d\\.]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Disease Name:\", \"Disease:\", \"Diagnosis:\"]:\n",
    "            pattern = re.compile(rf\"(?<!\\w){keyword}:\\s*([\\w\\s]+(?:[\\n\\w\\s]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Disease Details:\", \"Details:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w\\s.,-]+(?:[\\n\\w\\s.,-]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Medicines:\", \"Medication:\", \"Medicine:\", \"Injections:\", \"Oral:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w\\s.,-]+(?:[\\n\\w\\s.,-]+)*)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Bed Type:\", \"Bed:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\w\\s-]+)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Ventilation:\", \"Ventilator:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*(Yes|No)\", re.IGNORECASE)\n",
    "        elif keyword in [\"Other Charges:\", \"Charges:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}:\\s*([\\d\\.]+)\", re.IGNORECASE)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):\n",
    "            if match:\n",
    "                print(match.group(0)) #adding debugging line\n",
    "                extracted_text = match.group(1).strip()\n",
    "                extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "                extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "    print(extracted_info) #Debugging line\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        print(patient_values) #Debugging line\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b93964157247e1b44c9b8df8f05593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12603755569a4fe1a4bb515aaee086e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b70f5469fb242c3b561d1feed09f5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1d1ffd78634d41a3854db919961fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    print(text) # Debugging line\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        pattern = re.compile(rf\"{keyword}:\\s*(.*)\", re.IGNORECASE) #Simplified regex for test\n",
    "\n",
    "        for match in pattern.finditer(text):\n",
    "            if match:\n",
    "                print(match.group(0)) #adding debugging line\n",
    "                extracted_text = match.group(1).strip()\n",
    "                extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "                extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "    print(extracted_info) #Debugging line\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        print(patient_values) #Debugging line\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ee758befa342bfafeb02808d38aff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245a1a7946f14d1c8aec3f5355224294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    print(\"Text before regex:\")\n",
    "    print(text)  # Debugging line\n",
    "\n",
    "    extracted_info = []\n",
    "\n",
    "    for char in text:\n",
    "        print(ord(char), char)\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s:]', '', text)\n",
    "\n",
    "    print(\"Text after non alpha removal:\")\n",
    "    print(text)\n",
    "\n",
    "    for keyword in keywords:\n",
    "        pattern = re.compile(rf\"{keyword}:\\s*(.*)\", re.IGNORECASE)\n",
    "\n",
    "        for match in pattern.finditer(text):\n",
    "            if match:\n",
    "                print(match.group(0))\n",
    "                extracted_text = match.group(1).strip()\n",
    "                extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "                extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "    print(extracted_info)\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        print(patient_values) #Debugging line\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atleast Working Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9ba0d334f148e1a34b8926420cc11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd86908cb500467ca20d516f47a38b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\", \"Patient Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Father's Name:\", \"Father Name:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Aadhar Card:\", \"Aadhaar:\", \"Aadhar No:\", \"Aadhar\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\s-]+)\")\n",
    "        elif keyword in [\"Gender:\", \"Sex:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w]+)\")\n",
    "        elif keyword in [\"Blood Group:\", \"Blood:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w+-]+)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Hospital Name:\", \"Hospital\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Insurance ID:\", \"InsuranceID:\", \"Insurance Id\", \"Insurance\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\d-]+)\")\n",
    "        elif keyword in [\"Appointment Time:\", \"Appointment\", \"Time:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d:]+(?:\\s*[AP]M)?)\")\n",
    "        elif keyword in [\"Phone:\", \"Phone Number:\", \"Contact:\", \"Mobile:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\s-]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\", \"Total:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "        elif keyword in [\"Disease Name:\", \"Disease:\", \"Diagnosis:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Disease Details:\", \"Details:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s.,-]+(?:\\n[\\w\\s.,-]+)*)\")\n",
    "        elif keyword in [\"Medicines:\", \"Medication:\", \"Medicine:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s.,-]+(?:\\n[\\w\\s.,-]+)*)\")\n",
    "        elif keyword in [\"Bed Type:\", \"Bed:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+)\")\n",
    "        elif keyword in [\"Ventilation:\", \"Ventilator:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*(Yes|No)\")\n",
    "        elif keyword in [\"Other Charges:\", \"Charges:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):  # Use finditer to find all matches\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Remove any text after \"\\n\"\n",
    "            extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archisman's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ddd89aff434a77abd942a175e96a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad6f66cb06340fcb733434529176178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\", \"Patient Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Father's Name:\", \"Father Name:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Aadhar Card:\", \"Aadhaar:\", \"Aadhar No:\", \"Aadhar\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\s-]+)\")\n",
    "        elif keyword in [\"Gender:\", \"Sex:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w]+)\")\n",
    "        elif keyword in [\"Blood Group:\", \"Blood:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w+-]+)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Hospital Name:\", \"Hospital\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Insurance ID:\", \"InsuranceID:\", \"Insurance Id\", \"Insurance\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\d-]+)\")\n",
    "        elif keyword in [\"Appointment Time:\", \"Appointment\", \"Time:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d:]+(?:\\s*[AP]M)?)\")\n",
    "        elif keyword in [\"Phone:\", \"Phone Number:\", \"Contact:\", \"Mobile:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\s-]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\", \"Total:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "        elif keyword in [\"Disease Name:\", \"Disease:\", \"Diagnosis:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Disease Details:\", \"Details:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s.,-]+(?:\\n[\\w\\s.,-]+)*)\")\n",
    "        elif keyword in [\"Medicines:\", \"Medication:\", \"Medicine:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s.,-]+(?:\\n[\\w\\s.,-]+)*)\")\n",
    "        elif keyword in [\"Bed Type:\", \"Bed:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+)\")\n",
    "        elif keyword in [\"Ventilation:\", \"Ventilator:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*(Yes|No)\")\n",
    "        elif keyword in [\"Other Charges:\", \"Charges:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):  # Use finditer to find all matches\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Remove any text after \"\\n\"\n",
    "            extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archisman S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ee81439b6449b087549ee27087a38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbe452e675e4195b4a2fd907d1c8a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "    for keyword in keywords:\n",
    "        pattern = re.compile(rf\"{keyword}\\s*([\\w\\s.,-]+(?:\\n[\\w\\s.,-]+)*)\", re.IGNORECASE)\n",
    "        for match in pattern.finditer(text):\n",
    "            extracted_text = match.group(1).strip()\n",
    "            extracted_text = re.sub(r'\\n+', ' ', extracted_text)  # Remove extra newlines\n",
    "            if extracted_text:\n",
    "                extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "        cursor.execute(\"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\", (insurance_id, file_path))\n",
    "\n",
    "        insert_patient_query = \"\"\"\n",
    "        INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address,\n",
    "        hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type,\n",
    "        ventilation, other_charges)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        def get_value(label):\n",
    "            return next((item[\"Text\"] for item in data if item[\"Label\"] == label), None) or None  # Convert \"\" to None\n",
    "\n",
    "        patient_values = (\n",
    "            insurance_id, get_value(\"Name\"), get_value(\"Father's Name\"), get_value(\"Aadhar Card\"),\n",
    "            get_value(\"Gender\"), get_value(\"Blood Group\"), get_value(\"Address\"), get_value(\"Hospital Name\"),\n",
    "            get_value(\"Appointment Time\"), get_value(\"Phone Number\"), get_value(\"Amount\"),\n",
    "            get_value(\"Disease Name\"), get_value(\"Disease Details\"), get_value(\"Medicines\"),\n",
    "            get_value(\"Bed Type\"), get_value(\"Ventilation\"), get_value(\"Other Charges\")\n",
    "        )\n",
    "\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = extract_text_from_image(file_path) if file_path.lower().endswith(('.png', '.jpg', '.jpeg')) else extract_text_from_pdf(file_path)\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "file_chooser.register_callback(lambda chooser: process_file(chooser.selected) if chooser.selected else None)\n",
    "display(file_chooser, output_widget)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsuccessful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuming Work from previous atleast working Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d75ec5058744f35b196a7e0825736aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4a93a8015041f0bd4910788628a004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "\n",
    "    # Improve Aadhaar detection - try multiple patterns and formats\n",
    "    aadhaar_pattern = re.compile(r'(?:Aadhar|Aadhaar|AADHAAR|आधार)(?:\\s*(?:Card|Number|No|ID|#|:))?\\s*((?:\\d[\\d\\s-]*){12})')\n",
    "    aadhaar_matches = aadhaar_pattern.findall(text)\n",
    "    if aadhaar_matches:\n",
    "        # Clean up the Aadhaar number (remove spaces, dashes)\n",
    "        aadhaar = re.sub(r'[^\\d]', '', aadhaar_matches[0])\n",
    "        # Format as XXXX-XXXX-XXXX if it's 12 digits\n",
    "        if len(aadhaar) == 12:\n",
    "            formatted_aadhaar = f\"{aadhaar[:4]}-{aadhaar[4:8]}-{aadhaar[8:]}\"\n",
    "            extracted_info.append({\"Text\": formatted_aadhaar, \"Label\": \"Aadhar Card\"})\n",
    "\n",
    "    # Improve disease details extraction - handle multi-line content better\n",
    "    disease_details_pattern = re.compile(r'(?:Disease Details|Details|Diagnosis Details|Clinical Details|Medical Details|Condition Details)[:;]\\s*([\\w\\s,.;:()\\-/\\n]+)(?=\\n\\n|\\n[A-Z]|$)', re.IGNORECASE)\n",
    "    disease_details_matches = disease_details_pattern.search(text)\n",
    "    if disease_details_matches:\n",
    "        details = disease_details_matches.group(1).strip()\n",
    "        # Clean up the details\n",
    "        details = re.sub(r'\\n+', ' ', details)\n",
    "        details = re.sub(r'\\s+', ' ', details)\n",
    "        extracted_info.append({\"Text\": details, \"Label\": \"Disease Details\"})\n",
    "\n",
    "    # Improve medicines extraction\n",
    "    medicines_pattern = re.compile(r'(?:Medicines|Medications|Drugs|Prescriptions|Medicine List|Prescribed Medicines)[:;]\\s*([\\w\\s,.;:()\\-/\\n]+)(?=\\n\\n|\\n[A-Z]|$)', re.IGNORECASE)\n",
    "    medicines_matches = medicines_pattern.search(text)\n",
    "    if medicines_matches:\n",
    "        medicines = medicines_matches.group(1).strip()\n",
    "        # Clean up the medicines list\n",
    "        medicines = re.sub(r'\\n+', ' ', medicines)\n",
    "        medicines = re.sub(r'\\s+', ' ', medicines)\n",
    "        extracted_info.append({\"Text\": medicines, \"Label\": \"Medicines\"})\n",
    "\n",
    "    # Process other keywords as before\n",
    "    for keyword in keywords:\n",
    "        # Skip the fields we've already handled with specialized patterns\n",
    "        if any(term in keyword.lower() for term in [\"aadhar\", \"aadhaar\", \"disease details\", \"medicines\", \"medication\"]):\n",
    "            continue\n",
    "            \n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\", \"Patient Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Father's Name:\", \"Father Name:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Gender:\", \"Sex:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w]+)\")\n",
    "        elif keyword in [\"Blood Group:\", \"Blood:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w+-]+)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Hospital Name:\", \"Hospital\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Insurance ID:\", \"InsuranceID:\", \"Insurance Id\", \"Insurance\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\d-]+)\")\n",
    "        elif keyword in [\"Appointment Time:\", \"Appointment\", \"Time:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d:]+(?:\\s*[AP]M)?)\")\n",
    "        elif keyword in [\"Phone:\", \"Phone Number:\", \"Contact:\", \"Mobile:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\s-]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\", \"Total:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "        elif keyword in [\"Disease Name:\", \"Disease:\", \"Diagnosis:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Bed Type:\", \"Bed:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+)\")\n",
    "        elif keyword in [\"Ventilation:\", \"Ventilator:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*(Yes|No)\")\n",
    "        elif keyword in [\"Other Charges:\", \"Charges:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Improved handling of multi-line text - take first line only for certain fields\n",
    "            if keyword in [\"Name:\", \"Father's Name:\", \"Gender:\", \"Blood Group:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"]:\n",
    "                extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is happening to save the disease details in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cd11376b174c24989c15e58b847505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db3e04f6e6148ffb2d3c054b2de5ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    # This catches raw numbers that look like Aadhaar numbers\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    # This catches Aadhaar numbers that are labeled\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    # Use with caution as it might pick up other 12-digit numbers\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    extracted_info = []\n",
    "    \n",
    "    # Special extraction for Aadhaar number\n",
    "    aadhaar = extract_aadhaar_number(text)\n",
    "    if aadhaar:\n",
    "        # Format as XXXX-XXXX-XXXX\n",
    "        formatted_aadhaar = f\"{aadhaar[:4]}-{aadhaar[4:8]}-{aadhaar[8:]}\"\n",
    "        extracted_info.append({\"Text\": formatted_aadhaar, \"Label\": \"Aadhar Card\"})\n",
    "    \n",
    "    # Improve disease details extraction - handle multi-line content better\n",
    "    disease_details_pattern = re.compile(r'(?:Disease Details|Details|Diagnosis Details|Clinical Details|Medical Details|Condition Details)[:;]\\s*([\\w\\s,.;:()\\-/\\n]+)(?=\\n\\n|\\n[A-Z]|$)', re.IGNORECASE)\n",
    "    disease_details_matches = disease_details_pattern.search(text)\n",
    "    if disease_details_matches:\n",
    "        details = disease_details_matches.group(1).strip()\n",
    "        # Clean up the details\n",
    "        details = re.sub(r'\\n+', ' ', details)\n",
    "        details = re.sub(r'\\s+', ' ', details)\n",
    "        extracted_info.append({\"Text\": details, \"Label\": \"Disease Details\"})\n",
    "\n",
    "    # Improve medicines extraction\n",
    "    medicines_pattern = re.compile(r'(?:Medicines|Medications|Drugs|Prescriptions|Medicine List|Prescribed Medicines)[:;]\\s*([\\w\\s,.;:()\\-/\\n]+)(?=\\n\\n|\\n[A-Z]|$)', re.IGNORECASE)\n",
    "    medicines_matches = medicines_pattern.search(text)\n",
    "    if medicines_matches:\n",
    "        medicines = medicines_matches.group(1).strip()\n",
    "        # Clean up the medicines list\n",
    "        medicines = re.sub(r'\\n+', ' ', medicines)\n",
    "        medicines = re.sub(r'\\s+', ' ', medicines)\n",
    "        extracted_info.append({\"Text\": medicines, \"Label\": \"Medicines\"})\n",
    "\n",
    "    # Process other keywords as before\n",
    "    for keyword in keywords:\n",
    "        # Skip the fields we've already handled with specialized patterns\n",
    "        if any(term in keyword.lower() for term in [\"aadhar\", \"aadhaar\", \"disease details\", \"medicines\", \"medication\"]):\n",
    "            continue\n",
    "            \n",
    "        if keyword in [\"Name:\", \"Customer Name\", \"Recipient\", \"Name\", \"Patient Name\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Father's Name:\", \"Father Name:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Gender:\", \"Sex:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w]+)\")\n",
    "        elif keyword in [\"Blood Group:\", \"Blood:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w+-]+)\")\n",
    "        elif keyword in [\"Address:\", \"Address\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s,-]+(?:\\n[\\w\\s,-]+)*)\")\n",
    "        elif keyword in [\"Hospital Name:\", \"Hospital\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Insurance ID:\", \"InsuranceID:\", \"Insurance Id\", \"Insurance\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\d-]+)\")\n",
    "        elif keyword in [\"Appointment Time:\", \"Appointment\", \"Time:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d:]+(?:\\s*[AP]M)?)\")\n",
    "        elif keyword in [\"Phone:\", \"Phone Number:\", \"Contact:\", \"Mobile:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\s-]+)\")\n",
    "        elif keyword in [\"Amount:\", \"Amount\", \"Total:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "        elif keyword in [\"Disease Name:\", \"Disease:\", \"Diagnosis:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+(?:\\n[\\w\\s]+)*)\")\n",
    "        elif keyword in [\"Bed Type:\", \"Bed:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\w\\s]+)\")\n",
    "        elif keyword in [\"Ventilation:\", \"Ventilator:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*(Yes|No)\")\n",
    "        elif keyword in [\"Other Charges:\", \"Charges:\"]:\n",
    "            pattern = re.compile(rf\"{keyword}\\s*([\\d\\.]+)\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for match in pattern.finditer(text):\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # Improved handling of multi-line text - take first line only for certain fields\n",
    "            if keyword in [\"Name:\", \"Father's Name:\", \"Gender:\", \"Blood Group:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"]:\n",
    "                extracted_text = extracted_text.split(\"\\n\")[0].strip()\n",
    "            extracted_info.append({\"Text\": extracted_text, \"Label\": keyword.replace(\":\", \"\")})\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is extracting the adhaar number as well as medicines. But screwing up by adding unecessary details at the end of each expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5f5f7d4971488e8bc13f9618f154d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b68b02dde440fd805e5c8eebec74e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    # This catches raw numbers that look like Aadhaar numbers\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    # This catches Aadhaar numbers that are labeled\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    # Use with caution as it might pick up other 12-digit numbers\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "\n",
    "def clean_extracted_field(text, field_type):\n",
    "    \"\"\"\n",
    "    Cleans extracted text based on field type to remove common OCR artifacts\n",
    "    and mislabeled content\n",
    "    \"\"\"\n",
    "    # Convert to string in case we received another type\n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Remove common label text that might be captured within the value\n",
    "    unwanted_labels = [\n",
    "        \"Phone Number\", \"Contact\", \"Mobile\", \"Call\",\n",
    "        \"Hospital Name\", \"Doctor\", \"Clinic\", \"MD\", \"Dr\\\\.\",\n",
    "        \"Address\", \"Location\", \"Place\", \"Residence\",\n",
    "        \"Insurance ID\", \"Policy Number\", \"Insurance\",\n",
    "        \"Amount\", \"Total\", \"Fee\", \"Payment\",\n",
    "        \"Disease\", \"Diagnosis\", \"Condition\",\n",
    "        \"Medicines\", \"Medication\", \"Drugs\", \"Prescription\"\n",
    "    ]\n",
    "    \n",
    "    # For each unwanted label, try to remove it if it appears at the end\n",
    "    for label in unwanted_labels:\n",
    "        # Create pattern to match label at the end of the text (allowing for spaces)\n",
    "        pattern = rf'\\s*{re.escape(label)}$'\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove common field separators\n",
    "    text = re.sub(r'[:;|]$', '', text)\n",
    "    \n",
    "    # Clean up newlines and extra spaces\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Additional field-specific cleaning\n",
    "    if field_type in [\"Address\"]:\n",
    "        # Keep only relevant address information\n",
    "        text = re.sub(r'\\s*(?:Phone|Mobile|Contact|Email).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Hospital Name\"]:\n",
    "        # Remove doctor references\n",
    "        text = re.sub(r'\\s*(?:Doctor|Dr\\.|MD|Physician).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Phone Number\"]:\n",
    "        # Keep only digits and basic formatting characters\n",
    "        text = re.sub(r'[^\\d+\\-\\s()]', '', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def extract_fields_with_boundaries(text):\n",
    "    \"\"\"\n",
    "    Extract fields with improved boundary detection to prevent label bleed\n",
    "    \"\"\"\n",
    "    extracted_info = []\n",
    "    found_labels = set()\n",
    "    \n",
    "    # Dictionary of field patterns with better boundary detection\n",
    "    field_patterns = {\n",
    "        \"Name\": r'(?:Patient(?:\\s*Name)?|Name|Patient)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Father|Gender|Blood|Aadhaar))',\n",
    "        \"Father's Name\": r'(?:Father(?:[\\'s]*\\s*Name)?|Father)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Gender|Blood|Aadhaar))',\n",
    "        \"Gender\": r'(?:Gender|Sex)[:;]?\\s*(Male|Female|Other|M|F)(?=\\n|$)',\n",
    "        \"Blood Group\": r'(?:Blood(?:\\s*Group)?)[:;]?\\s*([ABO][+-]|AB[+-])(?=\\n|$)',\n",
    "        \"Address\": r'(?:Address|Location|Place|Residence)[:;]?\\s*([\\w\\s,\\.\\-\\/]+?)(?=\\n|$|(?:Phone|Mobile|Contact|Email))',\n",
    "        \"Hospital Name\": r'(?:Hospital(?:\\s*Name)?|Clinic|Medical Center)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Doctor|Dr|MD|Address))',\n",
    "        \"Insurance ID\": r'(?:Insurance(?:\\s*(?:ID|Number|No))?|Policy(?:\\s*Number)?)[:;]?\\s*([\\w\\d\\-]+?)(?=\\n|$)',\n",
    "        \"Appointment Time\": r'(?:Appointment(?:\\s*Time)?|Time|Schedule)[:;]?\\s*([\\d:]+(?:\\s*[AP]M)?)(?=\\n|$)',\n",
    "        \"Phone Number\": r'(?:Phone(?:\\s*Number)?|Mobile|Contact|Cell)[:;]?\\s*([\\d\\s\\+\\-\\(\\)]+?)(?=\\n|$)',\n",
    "        \"Amount\": r'(?:Amount|Total|Cost|Fee|Charges)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)',\n",
    "        \"Disease Name\": r'(?:Disease(?:\\s*Name)?|Diagnosis|Condition|Ailment)[:;]?\\s*([\\w\\s]+?)(?=\\n|$|(?:Disease Details|Symptoms|Treatment))',\n",
    "        \"Disease Details\": r'(?:Disease(?:\\s*Details)?|Details|Diagnosis Details|Clinical Details|Symptoms)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Medicines|Medications|Drugs)|$)',\n",
    "        \"Medicines\": r'(?:Medicines|Medications|Drugs|Prescriptions|Medicine List)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Bed|Ventilation|Amount|Charges)|$)',\n",
    "        \"Bed Type\": r'(?:Bed(?:\\s*Type)?)[:;]?\\s*([\\w\\s]+?)(?=\\n|$)',\n",
    "        \"Ventilation\": r'(?:Ventilation|Ventilator|Oxygen)[:;]?\\s*(Yes|No|Required|Not Required)(?=\\n|$)',\n",
    "        \"Other Charges\": r'(?:Other(?:\\s*Charges)?|Additional(?:\\s*Charges)?|Extra)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)'\n",
    "    }\n",
    "    \n",
    "    # 1. First pass: Extract Aadhaar number with dedicated function\n",
    "    aadhaar = extract_aadhaar_number(text)\n",
    "    if aadhaar:\n",
    "        formatted_aadhaar = f\"{aadhaar[:4]}-{aadhaar[4:8]}-{aadhaar[8:]}\"\n",
    "        extracted_info.append({\"Text\": formatted_aadhaar, \"Label\": \"Aadhar Card\"})\n",
    "        found_labels.add(\"Aadhar Card\")\n",
    "    \n",
    "    # 2. Second pass: Extract other fields with improved boundary detection\n",
    "    for label, pattern in field_patterns.items():\n",
    "        if label in found_labels:\n",
    "            continue\n",
    "            \n",
    "        matches = re.search(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            extracted_text = matches.group(1).strip()\n",
    "            # Clean the extracted text to remove potential label contamination\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            # Only add if we have meaningful content\n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    # 3. Third pass: Look for unlabeled numbers that might be specific fields\n",
    "    if \"Phone Number\" not in found_labels:\n",
    "        # Look for potential phone numbers (10-digit sequences)\n",
    "        phone_matches = re.search(r'(?<!\\d)(\\d{10})(?!\\d)', text)\n",
    "        if phone_matches:\n",
    "            extracted_info.append({\"Text\": phone_matches.group(1), \"Label\": \"Phone Number\"})\n",
    "            found_labels.add(\"Phone Number\")\n",
    "    \n",
    "    # Look for Appendicitis or other common conditions if disease name not found\n",
    "    if \"Disease Name\" not in found_labels:\n",
    "        common_diseases = [\"appendicitis\", \"diabetes\", \"hypertension\", \"cancer\", \"fracture\", \"pneumonia\"]\n",
    "        for disease in common_diseases:\n",
    "            if re.search(rf'\\b{disease}\\b', text, re.IGNORECASE):\n",
    "                extracted_info.append({\"Text\": disease.capitalize(), \"Label\": \"Disease Name\"})\n",
    "                found_labels.add(\"Disease Name\")\n",
    "                break\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    \"\"\"\n",
    "    Main processing function that combines extraction methods\n",
    "    \"\"\"\n",
    "    # Get fields using improved boundary detection\n",
    "    extracted_info = extract_fields_with_boundaries(text)\n",
    "    \n",
    "    # For backward compatibility, still use keyword-based extraction for any missing fields\n",
    "    found_labels = {item[\"Label\"] for item in extracted_info}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Skip keywords for fields we already found\n",
    "        label = keyword.replace(\":\", \"\").strip()\n",
    "        if any(label in existing for existing in found_labels):\n",
    "            continue\n",
    "            \n",
    "        # Simple keyword-based extraction as fallback\n",
    "        pattern = re.compile(rf\"{re.escape(keyword)}\\s*([\\w\\s\\d\\.\\-]+?)(?=\\n|$)\", re.IGNORECASE)\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# The extract_aadhaar_number function from previous solution should be included here\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        \n",
    "        # Clean the amount value to remove currency symbols and other non-numeric characters\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        if amount:\n",
    "            # Extract only the numeric part (keep decimal point)\n",
    "            amount = re.sub(r'[^\\d.]', '', amount)\n",
    "            # If there's still content after cleaning, convert to float\n",
    "            if amount:\n",
    "                try:\n",
    "                    amount = float(amount)\n",
    "                except ValueError:\n",
    "                    amount = None\n",
    "        \n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        \n",
    "        # Clean the other_charges value similarly\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "        if other_charges:\n",
    "            other_charges = re.sub(r'[^\\d.]', '', other_charges)\n",
    "            if other_charges:\n",
    "                try:\n",
    "                    other_charges = float(other_charges)\n",
    "                except ValueError:\n",
    "                    other_charges = None\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is mostly working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ae6583917f450a92d50557fc4390ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de46763b89ce4dd6b20844ca516cda6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    # This catches raw numbers that look like Aadhaar numbers\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    # This catches Aadhaar numbers that are labeled\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    # Use with caution as it might pick up other 12-digit numbers\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "\n",
    "def clean_extracted_field(text, field_type):\n",
    "    \"\"\"\n",
    "    Cleans extracted text based on field type to remove common OCR artifacts\n",
    "    and mislabeled content\n",
    "    \"\"\"\n",
    "    # Convert to string in case we received another type\n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Remove common label text that might be captured within the value\n",
    "    unwanted_labels = [\n",
    "        \"Phone Number\", \"Contact\", \"Mobile\", \"Call\",\n",
    "        \"Hospital Name\", \"Doctor\", \"Clinic\", \"MD\", \"Dr\\\\.\",\n",
    "        \"Address\", \"Location\", \"Place\", \"Residence\",\n",
    "        \"Insurance ID\", \"Policy Number\", \"Insurance\",\n",
    "        \"Amount\", \"Total\", \"Fee\", \"Payment\",\n",
    "        \"Disease\", \"Diagnosis\", \"Condition\",\n",
    "        \"Medicines\", \"Medication\", \"Drugs\", \"Prescription\"\n",
    "    ]\n",
    "    \n",
    "    # For each unwanted label, try to remove it if it appears at the end\n",
    "    for label in unwanted_labels:\n",
    "        # Create pattern to match label at the end of the text (allowing for spaces)\n",
    "        pattern = rf'\\s*{re.escape(label)}$'\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove common field separators\n",
    "    text = re.sub(r'[:;|]$', '', text)\n",
    "    \n",
    "    # Clean up newlines and extra spaces\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Additional field-specific cleaning\n",
    "    if field_type in [\"Address\"]:\n",
    "        # Keep only relevant address information\n",
    "        text = re.sub(r'\\s*(?:Phone|Mobile|Contact|Email).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Hospital Name\"]:\n",
    "        # Remove doctor references\n",
    "        text = re.sub(r'\\s*(?:Doctor|Dr\\.|MD|Physician).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Phone Number\"]:\n",
    "        # Keep only digits and basic formatting characters\n",
    "        text = re.sub(r'[^\\d+\\-\\s()]', '', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def extract_fields_with_boundaries(text):\n",
    "    \"\"\"\n",
    "    Extract fields with improved boundary detection to prevent label bleed\n",
    "    \"\"\"\n",
    "    extracted_info = []\n",
    "    found_labels = set()\n",
    "    \n",
    "    # Dictionary of field patterns with better boundary detection\n",
    "    field_patterns = {\n",
    "        \"Name\": r'(?:Patient(?:\\s*Name)?|Name|Patient)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Father|Gender|Blood|Aadhaar))',\n",
    "        \"Father's Name\": r'(?:Father(?:[\\'s]*\\s*Name)?|Father)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Gender|Blood|Aadhaar))',\n",
    "        \"Gender\": r'(?:Gender|Sex)[:;]?\\s*(Male|Female|Other|M|F)(?=\\n|$)',\n",
    "        \"Blood Group\": r'(?:Blood(?:\\s*Group)?)[:;]?\\s*([ABO][+-]|AB[+-])(?=\\n|$)',\n",
    "        \"Address\": r'(?:Address|Location|Place|Residence)[:;]?\\s*([\\w\\s,\\.\\-\\/]+?)(?=\\n|$|(?:Phone|Mobile|Contact|Email))',\n",
    "        \"Hospital Name\": r'(?:Hospital(?:\\s*Name)?|Clinic|Medical Center)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Doctor|Dr|MD|Address))',\n",
    "        \"Insurance ID\": r'(?:Insurance(?:\\s*(?:ID|Number|No))?|Policy(?:\\s*Number)?)[:;]?\\s*([\\w\\d\\-]+?)(?=\\n|$)',\n",
    "        \"Appointment Time\": r'(?:Appointment(?:\\s*Time)?|Time|Schedule)[:;]?\\s*([\\d:]+(?:\\s*[AP]M)?)(?=\\n|$)',\n",
    "        \"Phone Number\": r'(?:Phone(?:\\s*Number)?|Mobile|Contact|Cell)[:;]?\\s*([\\d\\s\\+\\-\\(\\)]+?)(?=\\n|$)',\n",
    "        \"Amount\": r'(?:Amount|Total|Cost|Fee|Charges)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)',\n",
    "        \"Disease Name\": r'(?:Disease(?:\\s*Name)?|Diagnosis|Condition|Ailment)[:;]?\\s*([\\w\\s]+?)(?=\\n|$|(?:Disease Details|Symptoms|Treatment))',\n",
    "        \"Disease Details\": r'(?:Disease(?:\\s*Details)?|Details|Diagnosis Details|Clinical Details|Symptoms)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Medicines|Medications|Drugs)|$)',\n",
    "        \"Medicines\": r'(?:Medicines|Medications|Drugs|Prescriptions|Medicine List)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Bed|Ventilation|Amount|Charges)|$)',\n",
    "        \"Bed Type\": r'(?:Bed(?:\\s*Type)?)[:;]?\\s*([\\w\\s]+?)(?=\\n|$)',\n",
    "        \"Ventilation\": r'(?:Ventilation|Ventilator|Oxygen)[:;]?\\s*(Yes|No|Required|Not Required)(?=\\n|$)',\n",
    "        \"Other Charges\": r'(?:Other(?:\\s*Charges)?|Additional(?:\\s*Charges)?|Extra)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)'\n",
    "    }\n",
    "    \n",
    "    # 1. First pass: Extract Aadhaar number with dedicated function\n",
    "    aadhaar = extract_aadhaar_number(text)\n",
    "    if aadhaar:\n",
    "        formatted_aadhaar = f\"{aadhaar[:4]}-{aadhaar[4:8]}-{aadhaar[8:]}\"\n",
    "        extracted_info.append({\"Text\": formatted_aadhaar, \"Label\": \"Aadhar Card\"})\n",
    "        found_labels.add(\"Aadhar Card\")\n",
    "    \n",
    "    # 2. Second pass: Extract other fields with improved boundary detection\n",
    "    for label, pattern in field_patterns.items():\n",
    "        if label in found_labels:\n",
    "            continue\n",
    "            \n",
    "        matches = re.search(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            extracted_text = matches.group(1).strip()\n",
    "            # Clean the extracted text to remove potential label contamination\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            # Only add if we have meaningful content\n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    # 3. Third pass: Look for unlabeled numbers that might be specific fields\n",
    "    if \"Phone Number\" not in found_labels:\n",
    "        # Look for potential phone numbers (10-digit sequences)\n",
    "        phone_matches = re.search(r'(?<!\\d)(\\d{10})(?!\\d)', text)\n",
    "        if phone_matches:\n",
    "            extracted_info.append({\"Text\": phone_matches.group(1), \"Label\": \"Phone Number\"})\n",
    "            found_labels.add(\"Phone Number\")\n",
    "    \n",
    "    # Look for Appendicitis or other common conditions if disease name not found\n",
    "    if \"Disease Name\" not in found_labels:\n",
    "        common_diseases = [\"appendicitis\", \"diabetes\", \"hypertension\", \"cancer\", \"fracture\", \"pneumonia\"]\n",
    "        for disease in common_diseases:\n",
    "            if re.search(rf'\\b{disease}\\b', text, re.IGNORECASE):\n",
    "                extracted_info.append({\"Text\": disease.capitalize(), \"Label\": \"Disease Name\"})\n",
    "                found_labels.add(\"Disease Name\")\n",
    "                break\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    \"\"\"\n",
    "    Main processing function that combines extraction methods\n",
    "    \"\"\"\n",
    "    # Get fields using improved boundary detection\n",
    "    extracted_info = extract_fields_with_boundaries(text)\n",
    "    \n",
    "    # For backward compatibility, still use keyword-based extraction for any missing fields\n",
    "    found_labels = {item[\"Label\"] for item in extracted_info}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Skip keywords for fields we already found\n",
    "        label = keyword.replace(\":\", \"\").strip()\n",
    "        if any(label in existing for existing in found_labels):\n",
    "            continue\n",
    "            \n",
    "        # Simple keyword-based extraction as fallback\n",
    "        pattern = re.compile(rf\"{re.escape(keyword)}\\s*([\\w\\s\\d\\.\\-]+?)(?=\\n|$)\", re.IGNORECASE)\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# The extract_aadhaar_number function from previous solution should be included here\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Insert patient details into the 'patient_details' table\n",
    "        insert_patient_query = \"INSERT INTO patient_details (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        \n",
    "        # Clean the amount value to remove currency symbols and other non-numeric characters\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        if amount:\n",
    "            # Extract only the numeric part (keep decimal point)\n",
    "            amount = re.sub(r'[^\\d.]', '', amount)\n",
    "            # If there's still content after cleaning, convert to float\n",
    "            if amount:\n",
    "                try:\n",
    "                    amount = float(amount)\n",
    "                except ValueError:\n",
    "                    amount = None\n",
    "        \n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        \n",
    "        # Handle ventilation field - convert N/A, NULL, etc. to \"No\"\n",
    "        ventilation = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Ventilation\"), None)\n",
    "        if ventilation is None or ventilation.upper() in [\"N/A\", \"NA\", \"NULL\", \"\"]:\n",
    "            ventilation = \"No\"\n",
    "        \n",
    "        # Clean the other_charges value similarly\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "        if other_charges:\n",
    "            other_charges = re.sub(r'[^\\d.]', '', other_charges)\n",
    "            if other_charges:\n",
    "                try:\n",
    "                    other_charges = float(other_charges)\n",
    "                except ValueError:\n",
    "                    other_charges = None\n",
    "\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, address, hospital_name, appointment_time, phone_number, amount, disease_name, disease_details, medicines, bed_type, ventilation, other_charges)\n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ventilation part is fucking up. So we have decided to delete the ventilation column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c171fefcbdf4145bfad51ef99644c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2de385f6cc84d939ca2605cbdccc56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    # This catches raw numbers that look like Aadhaar numbers\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    # This catches Aadhaar numbers that are labeled\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    # Use with caution as it might pick up other 12-digit numbers\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "\n",
    "def clean_extracted_field(text, field_type):\n",
    "    \"\"\"\n",
    "    Cleans extracted text based on field type to remove common OCR artifacts\n",
    "    and mislabeled content\n",
    "    \"\"\"\n",
    "    # Convert to string in case we received another type\n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Remove common label text that might be captured within the value\n",
    "    unwanted_labels = [\n",
    "        \"Phone Number\", \"Contact\", \"Mobile\", \"Call\",\n",
    "        \"Hospital Name\", \"Doctor\", \"Clinic\", \"MD\", \"Dr\\\\.\",\n",
    "        \"Address\", \"Location\", \"Place\", \"Residence\",\n",
    "        \"Insurance ID\", \"Policy Number\", \"Insurance\",\n",
    "        \"Amount\", \"Total\", \"Fee\", \"Payment\",\n",
    "        \"Disease\", \"Diagnosis\", \"Condition\",\n",
    "        \"Medicines\", \"Medication\", \"Drugs\", \"Prescription\"\n",
    "    ]\n",
    "    \n",
    "    # For each unwanted label, try to remove it if it appears at the end\n",
    "    for label in unwanted_labels:\n",
    "        # Create pattern to match label at the end of the text (allowing for spaces)\n",
    "        pattern = rf'\\s*{re.escape(label)}$'\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove common field separators\n",
    "    text = re.sub(r'[:;|]$', '', text)\n",
    "    \n",
    "    # Clean up newlines and extra spaces\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Additional field-specific cleaning\n",
    "    if field_type in [\"Address\"]:\n",
    "        # Keep only relevant address information\n",
    "        text = re.sub(r'\\s*(?:Phone|Mobile|Contact|Email).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Hospital Name\"]:\n",
    "        # Remove doctor references\n",
    "        text = re.sub(r'\\s*(?:Doctor|Dr\\.|MD|Physician).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Phone Number\"]:\n",
    "        # Keep only digits and basic formatting characters\n",
    "        text = re.sub(r'[^\\d+\\-\\s()]', '', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def extract_fields_with_boundaries(text):\n",
    "    \"\"\"\n",
    "    Extract fields with improved boundary detection to prevent label bleed\n",
    "    \"\"\"\n",
    "    extracted_info = []\n",
    "    found_labels = set()\n",
    "    \n",
    "    # Dictionary of field patterns with better boundary detection\n",
    "    field_patterns = {\n",
    "        \"Name\": r'(?:Patient(?:\\s*Name)?|Name|Patient)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Father|Gender|Blood|Aadhaar))',\n",
    "        \"Father's Name\": r'(?:Father(?:[\\'s]*\\s*Name)?|Father)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Gender|Blood|Aadhaar))',\n",
    "        \"Gender\": r'(?:Gender|Sex)[:;]?\\s*(Male|Female|Other|M|F)(?=\\n|$)',\n",
    "        \"Blood Group\": r'(?:Blood(?:\\s*Group)?)[:;]?\\s*([ABO][+-]|AB[+-])(?=\\n|$)',\n",
    "        \"Address\": r'(?:Address|Location|Place|Residence)[:;]?\\s*([\\w\\s,\\.\\-\\/]+?)(?=\\n|$|(?:Phone|Mobile|Contact|Email))',\n",
    "        \"Hospital Name\": r'(?:Hospital(?:\\s*Name)?|Clinic|Medical Center)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Doctor|Dr|MD|Address))',\n",
    "        \"Insurance ID\": r'(?:Insurance(?:\\s*(?:ID|Number|No))?|Policy(?:\\s*Number)?)[:;]?\\s*([\\w\\d\\-]+?)(?=\\n|$)',\n",
    "        \"Appointment Time\": r'(?:Appointment(?:\\s*Time)?|Time|Schedule)[:;]?\\s*([\\d:]+(?:\\s*[AP]M)?)(?=\\n|$)',\n",
    "        \"Phone Number\": r'(?:Phone(?:\\s*Number)?|Mobile|Contact|Cell)[:;]?\\s*([\\d\\s\\+\\-\\(\\)]+?)(?=\\n|$)',\n",
    "        \"Amount\": r'(?:Amount|Total|Cost|Fee|Charges)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)',\n",
    "        \"Disease Name\": r'(?:Disease(?:\\s*Name)?|Diagnosis|Condition|Ailment)[:;]?\\s*([\\w\\s]+?)(?=\\n|$|(?:Disease Details|Symptoms|Treatment))',\n",
    "        \"Disease Details\": r'(?:Disease(?:\\s*Details)?|Details|Diagnosis Details|Clinical Details|Symptoms)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Medicines|Medications|Drugs)|$)',\n",
    "        \"Medicines\": r'(?:Medicines|Medications|Drugs|Prescriptions|Medicine List)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Bed|Ventilation|Amount|Charges)|$)',\n",
    "        \"Bed Type\": r'(?:Bed(?:\\s*Type)?)[:;]?\\s*([\\w\\s]+?)(?=\\n|$)',\n",
    "        \"Ventilation\": r'(?:Ventilation|Ventilator|Oxygen)[:;]?\\s*(Yes|No|Required|Not Required)(?=\\n|$)',\n",
    "        \"Other Charges\": r'(?:Other(?:\\s*Charges)?|Additional(?:\\s*Charges)?|Extra)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)'\n",
    "    }\n",
    "    \n",
    "    # 1. First pass: Extract Aadhaar number with dedicated function\n",
    "    aadhaar = extract_aadhaar_number(text)\n",
    "    if aadhaar:\n",
    "        formatted_aadhaar = f\"{aadhaar[:4]}-{aadhaar[4:8]}-{aadhaar[8:]}\"\n",
    "        extracted_info.append({\"Text\": formatted_aadhaar, \"Label\": \"Aadhar Card\"})\n",
    "        found_labels.add(\"Aadhar Card\")\n",
    "    \n",
    "    # 2. Second pass: Extract other fields with improved boundary detection\n",
    "    for label, pattern in field_patterns.items():\n",
    "        if label in found_labels:\n",
    "            continue\n",
    "            \n",
    "        matches = re.search(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            extracted_text = matches.group(1).strip()\n",
    "            # Clean the extracted text to remove potential label contamination\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            # Only add if we have meaningful content\n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    # 3. Third pass: Look for unlabeled numbers that might be specific fields\n",
    "    if \"Phone Number\" not in found_labels:\n",
    "        # Look for potential phone numbers (10-digit sequences)\n",
    "        phone_matches = re.search(r'(?<!\\d)(\\d{10})(?!\\d)', text)\n",
    "        if phone_matches:\n",
    "            extracted_info.append({\"Text\": phone_matches.group(1), \"Label\": \"Phone Number\"})\n",
    "            found_labels.add(\"Phone Number\")\n",
    "    \n",
    "    # Look for Appendicitis or other common conditions if disease name not found\n",
    "    if \"Disease Name\" not in found_labels:\n",
    "        common_diseases = [\"appendicitis\", \"diabetes\", \"hypertension\", \"cancer\", \"fracture\", \"pneumonia\"]\n",
    "        for disease in common_diseases:\n",
    "            if re.search(rf'\\b{disease}\\b', text, re.IGNORECASE):\n",
    "                extracted_info.append({\"Text\": disease.capitalize(), \"Label\": \"Disease Name\"})\n",
    "                found_labels.add(\"Disease Name\")\n",
    "                break\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    \"\"\"\n",
    "    Main processing function that combines extraction methods\n",
    "    \"\"\"\n",
    "    # Get fields using improved boundary detection\n",
    "    extracted_info = extract_fields_with_boundaries(text)\n",
    "    \n",
    "    # For backward compatibility, still use keyword-based extraction for any missing fields\n",
    "    found_labels = {item[\"Label\"] for item in extracted_info}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Skip keywords for fields we already found\n",
    "        label = keyword.replace(\":\", \"\").strip()\n",
    "        if any(label in existing for existing in found_labels):\n",
    "            continue\n",
    "            \n",
    "        # Simple keyword-based extraction as fallback\n",
    "        pattern = re.compile(rf\"{re.escape(keyword)}\\s*([\\w\\s\\d\\.\\-]+?)(?=\\n|$)\", re.IGNORECASE)\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# The extract_aadhaar_number function from previous solution should be included here\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Modified query to exclude the ventilation column\n",
    "        insert_patient_query = \"\"\"\n",
    "        INSERT INTO patient_details \n",
    "        (insurance_id, name, father_name, aadhar_card, gender, blood_group, \n",
    "        address, hospital_name, appointment_time, phone_number, amount, \n",
    "        disease_name, disease_details, medicines, bed_type, other_charges) \n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        appointment_time = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Appointment Time\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        \n",
    "        # Clean the amount value\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        if amount:\n",
    "            amount = re.sub(r'[^\\d.]', '', amount)\n",
    "            if amount:\n",
    "                try:\n",
    "                    amount = float(amount)\n",
    "                except ValueError:\n",
    "                    amount = None\n",
    "        \n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        \n",
    "        # Clean other_charges\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "        if other_charges:\n",
    "            other_charges = re.sub(r'[^\\d.]', '', other_charges)\n",
    "            if other_charges:\n",
    "                try:\n",
    "                    other_charges = float(other_charges)\n",
    "                except ValueError:\n",
    "                    other_charges = None\n",
    "\n",
    "        # Note: ventilation is removed from the values tuple\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, \n",
    "                          address, hospital_name, appointment_time, phone_number, amount, \n",
    "                          disease_name, disease_details, medicines, bed_type, other_charges)\n",
    "        \n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Appointment Time:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing appointment_time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71440d3ac7664fc39f79b7b4254daec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/ankittalukder/Documents/NeuraClaim', filename='', title='', show_hidden=False, select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc7e017b4dc401aac06099c8a2818c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Output widget for displaying extracted text and information\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# MySQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"ankit2061\",\n",
    "    \"database\": \"ClaimDetails\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        with output_widget:\n",
    "            print(\"Error: Could not read the image. Please check the file format and path.\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_image = cv2.dilate(binary, kernel, iterations=1)\n",
    "    processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    if preprocessed_image is None:\n",
    "        return \"\"\n",
    "\n",
    "    pil_image = Image.fromarray(preprocessed_image)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "    except pytesseract.TesseractError as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Tesseract Error: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    # This catches raw numbers that look like Aadhaar numbers\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    # This catches Aadhaar numbers that are labeled\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    # Use with caution as it might pick up other 12-digit numbers\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "\n",
    "def clean_extracted_field(text, field_type):\n",
    "    \"\"\"\n",
    "    Cleans extracted text based on field type to remove common OCR artifacts\n",
    "    and mislabeled content\n",
    "    \"\"\"\n",
    "    # Convert to string in case we received another type\n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Remove common label text that might be captured within the value\n",
    "    unwanted_labels = [\n",
    "        \"Phone Number\", \"Contact\", \"Mobile\", \"Call\",\n",
    "        \"Hospital Name\", \"Doctor\", \"Clinic\", \"MD\", \"Dr\\\\.\",\n",
    "        \"Address\", \"Location\", \"Place\", \"Residence\",\n",
    "        \"Insurance ID\", \"Policy Number\", \"Insurance\",\n",
    "        \"Amount\", \"Total\", \"Fee\", \"Payment\",\n",
    "        \"Disease\", \"Diagnosis\", \"Condition\",\n",
    "        \"Medicines\", \"Medication\", \"Drugs\", \"Prescription\"\n",
    "    ]\n",
    "    \n",
    "    # For each unwanted label, try to remove it if it appears at the end\n",
    "    for label in unwanted_labels:\n",
    "        # Create pattern to match label at the end of the text (allowing for spaces)\n",
    "        pattern = rf'\\s*{re.escape(label)}$'\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove common field separators\n",
    "    text = re.sub(r'[:;|]$', '', text)\n",
    "    \n",
    "    # Clean up newlines and extra spaces\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Additional field-specific cleaning\n",
    "    if field_type in [\"Address\"]:\n",
    "        # Keep only relevant address information\n",
    "        text = re.sub(r'\\s*(?:Phone|Mobile|Contact|Email).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Hospital Name\"]:\n",
    "        # Remove doctor references\n",
    "        text = re.sub(r'\\s*(?:Doctor|Dr\\.|MD|Physician).*$', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    elif field_type in [\"Phone Number\"]:\n",
    "        # Keep only digits and basic formatting characters\n",
    "        text = re.sub(r'[^\\d+\\-\\s()]', '', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def extract_fields_with_boundaries(text):\n",
    "    \"\"\"\n",
    "    Extract fields with improved boundary detection to prevent label bleed\n",
    "    \"\"\"\n",
    "    extracted_info = []\n",
    "    found_labels = set()\n",
    "    \n",
    "    # Dictionary of field patterns with better boundary detection\n",
    "    field_patterns = {\n",
    "        \"Name\": r'(?:Patient(?:\\s*Name)?|Name|Patient)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Father|Gender|Blood|Aadhaar))',\n",
    "        \"Father's Name\": r'(?:Father(?:[\\'s]*\\s*Name)?|Father)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Gender|Blood|Aadhaar))',\n",
    "        \"Gender\": r'(?:Gender|Sex)[:;]?\\s*(Male|Female|Other|M|F)(?=\\n|$)',\n",
    "        \"Blood Group\": r'(?:Blood(?:\\s*Group)?)[:;]?\\s*([ABO][+-]|AB[+-])(?=\\n|$)',\n",
    "        \"Address\": r'(?:Address|Location|Place|Residence)[:;]?\\s*([\\w\\s,\\.\\-\\/]+?)(?=\\n|$|(?:Phone|Mobile|Contact|Email))',\n",
    "        \"Hospital Name\": r'(?:Hospital(?:\\s*Name)?|Clinic|Medical Center)[:;]?\\s*([\\w\\s\\.]+?)(?=\\n|$|(?:Doctor|Dr|MD|Address))',\n",
    "        \"Insurance ID\": r'(?:Insurance(?:\\s*(?:ID|Number|No))?|Policy(?:\\s*Number)?)[:;]?\\s*([\\w\\d\\-]+?)(?=\\n|$)',\n",
    "        \"Phone Number\": r'(?:Phone(?:\\s*Number)?|Mobile|Contact|Cell)[:;]?\\s*([\\d\\s\\+\\-\\(\\)]+?)(?=\\n|$)',\n",
    "        \"Amount\": r'(?:Amount|Total|Cost|Fee|Charges)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)',\n",
    "        \"Disease Name\": r'(?:Disease(?:\\s*Name)?|Diagnosis|Condition|Ailment)[:;]?\\s*([\\w\\s]+?)(?=\\n|$|(?:Disease Details|Symptoms|Treatment))',\n",
    "        \"Disease Details\": r'(?:Disease(?:\\s*Details)?|Details|Diagnosis Details|Clinical Details|Symptoms)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Medicines|Medications|Drugs)|$)',\n",
    "        \"Medicines\": r'(?:Medicines|Medications|Drugs|Prescriptions|Medicine List)[:;]?\\s*([\\w\\s,\\.;\\(\\)\\-\\/]+?)(?=\\n\\n|\\n(?:Bed|Ventilation|Amount|Charges)|$)',\n",
    "        \"Bed Type\": r'(?:Bed(?:\\s*Type)?)[:;]?\\s*([\\w\\s]+?)(?=\\n|$)',\n",
    "        \"Ventilation\": r'(?:Ventilation|Ventilator|Oxygen)[:;]?\\s*(Yes|No|Required|Not Required)(?=\\n|$)',\n",
    "        \"Other Charges\": r'(?:Other(?:\\s*Charges)?|Additional(?:\\s*Charges)?|Extra)[:;]?\\s*([\\d\\.]+?)(?=\\n|$|Rs|\\$|₹)'\n",
    "    }\n",
    "    \n",
    "    # 1. First pass: Extract Aadhaar number with dedicated function\n",
    "    aadhaar = extract_aadhaar_number(text)\n",
    "    if aadhaar:\n",
    "        formatted_aadhaar = f\"{aadhaar[:4]}-{aadhaar[4:8]}-{aadhaar[8:]}\"\n",
    "        extracted_info.append({\"Text\": formatted_aadhaar, \"Label\": \"Aadhar Card\"})\n",
    "        found_labels.add(\"Aadhar Card\")\n",
    "    \n",
    "    # 2. Second pass: Extract other fields with improved boundary detection\n",
    "    for label, pattern in field_patterns.items():\n",
    "        if label in found_labels:\n",
    "            continue\n",
    "            \n",
    "        matches = re.search(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            extracted_text = matches.group(1).strip()\n",
    "            # Clean the extracted text to remove potential label contamination\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            # Only add if we have meaningful content\n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    # 3. Third pass: Look for unlabeled numbers that might be specific fields\n",
    "    if \"Phone Number\" not in found_labels:\n",
    "        # Look for potential phone numbers (10-digit sequences)\n",
    "        phone_matches = re.search(r'(?<!\\d)(\\d{10})(?!\\d)', text)\n",
    "        if phone_matches:\n",
    "            extracted_info.append({\"Text\": phone_matches.group(1), \"Label\": \"Phone Number\"})\n",
    "            found_labels.add(\"Phone Number\")\n",
    "    \n",
    "    # Look for Appendicitis or other common conditions if disease name not found\n",
    "    if \"Disease Name\" not in found_labels:\n",
    "        common_diseases = [\"appendicitis\", \"diabetes\", \"hypertension\", \"cancer\", \"fracture\", \"pneumonia\"]\n",
    "        for disease in common_diseases:\n",
    "            if re.search(rf'\\b{disease}\\b', text, re.IGNORECASE):\n",
    "                extracted_info.append({\"Text\": disease.capitalize(), \"Label\": \"Disease Name\"})\n",
    "                found_labels.add(\"Disease Name\")\n",
    "                break\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "def process_text(text, keywords=[]):\n",
    "    \"\"\"\n",
    "    Main processing function that combines extraction methods\n",
    "    \"\"\"\n",
    "    # Get fields using improved boundary detection\n",
    "    extracted_info = extract_fields_with_boundaries(text)\n",
    "    \n",
    "    # For backward compatibility, still use keyword-based extraction for any missing fields\n",
    "    found_labels = {item[\"Label\"] for item in extracted_info}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Skip keywords for fields we already found\n",
    "        label = keyword.replace(\":\", \"\").strip()\n",
    "        if any(label in existing for existing in found_labels):\n",
    "            continue\n",
    "            \n",
    "        # Simple keyword-based extraction as fallback\n",
    "        pattern = re.compile(rf\"{re.escape(keyword)}\\s*([\\w\\s\\d\\.\\-]+?)(?=\\n|$)\", re.IGNORECASE)\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            cleaned_text = clean_extracted_field(extracted_text, label)\n",
    "            \n",
    "            if cleaned_text and len(cleaned_text) > 0:\n",
    "                extracted_info.append({\"Text\": cleaned_text, \"Label\": label})\n",
    "                found_labels.add(label)\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "# The extract_aadhaar_number function from previous solution should be included here\n",
    "def extract_aadhaar_number(text):\n",
    "    \"\"\"\n",
    "    Specialized function to extract Aadhaar numbers using multiple approaches\n",
    "    \"\"\"\n",
    "    # Clean the text first - this can help with OCR errors\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Method 1: Look for common Aadhaar number patterns (12 digits with or without separators)\n",
    "    aadhaar_patterns = [\n",
    "        # Pattern with no separators - 12 consecutive digits\n",
    "        r'(?<!\\d)(\\d{12})(?!\\d)',\n",
    "        # Pattern with space separators\n",
    "        r'(\\d{4}\\s+\\d{4}\\s+\\d{4})',\n",
    "        # Pattern with dash separators\n",
    "        r'(\\d{4}-\\d{4}-\\d{4})',\n",
    "        # Pattern with dot separators\n",
    "        r'(\\d{4}\\.\\d{4}\\.\\d{4})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in aadhaar_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text)\n",
    "        if matches:\n",
    "            # Clean up the found number (remove spaces, dashes)\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 2: Look for Aadhaar numbers with keywords\n",
    "    keyword_patterns = [\n",
    "        # Various ways \"Aadhaar\" might be written followed by a number\n",
    "        r'(?:aadhar|aadhaar|adhar|aadha+r|आधार)(?:\\s*(?:card|number|no|id|#|:|नंबर|संख्या))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        r'(?:uid|unique\\s+id)(?:\\s*(?:number|no|#))?\\s*[:\\.\\-]?\\s*((?:\\d[\\d\\s\\.\\-]*){12})',\n",
    "        # Looking for \"No:\" or \"Number:\" followed by what could be an Aadhaar\n",
    "        r'(?:no|number|id)?\\s*[:\\.\\-]\\s*((?:\\d[\\d\\s\\.\\-]*){12})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in keyword_patterns:\n",
    "        matches = re.findall(pattern, cleaned_text.lower())\n",
    "        if matches:\n",
    "            # Clean up the found number\n",
    "            aadhaar = re.sub(r'[^\\d]', '', matches[0])\n",
    "            if len(aadhaar) == 12:\n",
    "                return aadhaar\n",
    "    \n",
    "    # Method 3: More aggressive - find any 12-digit sequence that could be an Aadhaar number\n",
    "    digit_sequences = re.findall(r'(?<!\\d)(\\d[\\d\\s\\.\\-]*\\d)(?!\\d)', cleaned_text)\n",
    "    for seq in digit_sequences:\n",
    "        digits_only = re.sub(r'[^\\d]', '', seq)\n",
    "        if len(digits_only) == 12:\n",
    "            return digits_only\n",
    "            \n",
    "    return None\n",
    "def save_to_database(data, insurance_id, file_path):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "\n",
    "        # Insert document information into the 'patient_documents' table\n",
    "        insert_doc_query = \"INSERT INTO patient_documents (insurance_id, file_path) VALUES (%s, %s)\"\n",
    "        doc_values = (insurance_id, file_path)\n",
    "        cursor.execute(insert_doc_query, doc_values)\n",
    "\n",
    "        # Modified query to exclude the ventilation and appointment_time columns\n",
    "        insert_patient_query = \"\"\"\n",
    "        INSERT INTO patient_details \n",
    "        (insurance_id, name, father_name, aadhar_card, gender, blood_group, \n",
    "        address, hospital_name, phone_number, amount, \n",
    "        disease_name, disease_details, medicines, bed_type, other_charges) \n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Name\"), None)\n",
    "        father_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Father's Name\"), None)\n",
    "        aadhar_card = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Aadhar Card\"), None)\n",
    "        gender = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Gender\"), None)\n",
    "        blood_group = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Blood Group\"), None)\n",
    "        address = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Address\"), None)\n",
    "        hospital_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Hospital Name\"), None)\n",
    "        phone_number = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Phone Number\"), None)\n",
    "        \n",
    "        # Clean the amount value\n",
    "        amount = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Amount\"), None)\n",
    "        if amount:\n",
    "            amount = re.sub(r'[^\\d.]', '', amount)\n",
    "            if amount:\n",
    "                try:\n",
    "                    amount = float(amount)\n",
    "                except ValueError:\n",
    "                    amount = None\n",
    "        \n",
    "        disease_name = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Name\"), None)\n",
    "        disease_details = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Disease Details\"), None)\n",
    "        medicines = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Medicines\"), None)\n",
    "        bed_type = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Bed Type\"), None)\n",
    "        \n",
    "        # Clean other_charges\n",
    "        other_charges = next((item[\"Text\"] for item in data if item[\"Label\"] == \"Other Charges\"), None)\n",
    "        if other_charges:\n",
    "            other_charges = re.sub(r'[^\\d.]', '', other_charges)\n",
    "            if other_charges:\n",
    "                try:\n",
    "                    other_charges = float(other_charges)\n",
    "                except ValueError:\n",
    "                    other_charges = None\n",
    "\n",
    "        # Note: ventilation and appointment_time are removed from the values tuple\n",
    "        patient_values = (insurance_id, name, father_name, aadhar_card, gender, blood_group, \n",
    "                          address, hospital_name, phone_number, amount, \n",
    "                          disease_name, disease_details, medicines, bed_type, other_charges)\n",
    "        \n",
    "        cursor.execute(insert_patient_query, patient_values)\n",
    "\n",
    "        cnx.commit()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        with output_widget:\n",
    "            print(\"Data saved to database successfully.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        with output_widget:\n",
    "            print(f\"Error saving to database: {err}\")\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            text = extract_text_from_image(file_path)\n",
    "        elif file_path.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            if not text.strip():\n",
    "                print(\"Error: No text detected in the file.\")\n",
    "                return\n",
    "\n",
    "            print(\"Full Extracted Text:\", text)\n",
    "\n",
    "            important_info = process_text(text, [\"Name:\", \"Father's Name:\", \"Aadhar Card:\", \"Gender:\", \"Blood Group:\", \"Address:\", \"Hospital Name:\", \"Insurance ID:\", \"Phone Number:\", \"Amount:\", \"Disease Name:\", \"Disease Details:\", \"Medicines:\", \"Bed Type:\", \"Ventilation:\", \"Other Charges:\"])\n",
    "            if important_info:\n",
    "                display(Markdown(\"### Important Extracted Information:\"))\n",
    "                df = pd.DataFrame(important_info)\n",
    "                display(df)\n",
    "\n",
    "                insurance_id_data = next((item[\"Text\"] for item in important_info if item[\"Label\"] == \"Insurance ID\"), None)\n",
    "\n",
    "                if insurance_id_data is None:\n",
    "                    print(\"Error: Insurance ID not found. Data not saved.\")\n",
    "                    return\n",
    "\n",
    "                save_to_database(important_info, insurance_id_data, file_path)\n",
    "            else:\n",
    "                display(Markdown(\"**No important information found.**\"))\n",
    "    except Exception as e:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_chooser = FileChooser()\n",
    "\n",
    "def on_file_chosen(chooser):\n",
    "    if chooser.selected:\n",
    "        process_file(chooser.selected)\n",
    "\n",
    "file_chooser.register_callback(on_file_chosen)\n",
    "\n",
    "display(file_chooser, output_widget)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Caskroom/miniconda/base/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
